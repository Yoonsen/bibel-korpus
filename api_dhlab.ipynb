{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29f36eb0-83f2-4bca-91a9-36fee510902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dhlab as dh\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9113f7b6-307c-4d41-945c-a319b96811e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = dh.Corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3de0d40c-7ea1-424a-9d57-c1aa58bc640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_excel(\"bibelkorpus-bare bibler csv (1).xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d208615-cb0f-4744-b6c0-ddc3d465f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.extend_from_identifiers(d.urn.fillna(\"\").to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e2e4ccd-9c59-4b2a-857f-1eacda5e4e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ee61672-b6de-4878-b50e-620e83174027",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.to_csv(\"bibel-korpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9efd6d2d-681e-4451-bac7-667a57db1cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dhlab.api.dhlab_api as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a101d37-4fcd-4a66-99bb-0baf0f5582fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api.nb.no/dhlab'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.BASE_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d227fde-7006-4edf-9fe9-88633c2bec99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m\n",
       "api.concordance(\n",
       "    urns: list | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    words: str | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    window: int = \u001b[32m25\u001b[39m,\n",
       "    limit: int = \u001b[32m100\u001b[39m,\n",
       ") -> pandas.core.frame.DataFrame\n",
       "\u001b[31mSource:\u001b[39m   \n",
       "\u001b[38;5;28;01mdef\u001b[39;00m concordance(\n",
       "    urns: list | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, words: str | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, window: int = \u001b[32m25\u001b[39m, limit: int = \u001b[32m100\u001b[39m\n",
       ") -> DataFrame:\n",
       "    \u001b[33m\"\"\"Get a list of concordances from the National Library's database.\u001b[39m\n",
       "\n",
       "\u001b[33m    Call the API :py:obj:`~dhlab.constants.BASE_URL` endpoint\u001b[39m\n",
       "\u001b[33m    `/conc <https://api.nb.no/dhlab/#/default/post_conc>`_.\u001b[39m\n",
       "\n",
       "\u001b[33m    :param list urns: uniform resource names, for example:\u001b[39m\n",
       "\u001b[33m        ``[\"URN:NBN:no-nb_digibok_2008051404065\", \"URN:NBN:no-nb_digibok_2010092120011\"]``\u001b[39m\n",
       "\u001b[33m    :param str words: Word(s) to search for.\u001b[39m\n",
       "\u001b[33m        Can be an SQLite fulltext query, an fts5 string search expression.\u001b[39m\n",
       "\u001b[33m    :param int window: number of tokens on either side to show in the collocations, between 1-25.\u001b[39m\n",
       "\u001b[33m    :param int limit: max. number of concordances per document. Maximum value is 1000.\u001b[39m\n",
       "\u001b[33m    :return: a table of concordances\u001b[39m\n",
       "\u001b[33m    \"\"\"\u001b[39m\n",
       "    \u001b[38;5;28;01mif\u001b[39;00m words \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
       "        \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame(columns=[\u001b[33m\"index\"\u001b[39m, \u001b[33m\"docid\"\u001b[39m, \u001b[33m\"urn\"\u001b[39m, \u001b[33m\"conc\"\u001b[39m])  \u001b[38;5;66;03m# exit condition\u001b[39;00m\n",
       "    \u001b[38;5;28;01melse\u001b[39;00m:\n",
       "        params = {\u001b[33m\"urns\"\u001b[39m: urns, \u001b[33m\"query\"\u001b[39m: words, \u001b[33m\"window\"\u001b[39m: window, \u001b[33m\"limit\"\u001b[39m: limit}\n",
       "        r = api_post(BASE_URL + \u001b[33m\"/conc\"\u001b[39m, json=params)\n",
       "    \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame(r.json())\n",
       "\u001b[31mFile:\u001b[39m      ~/Github/bibel-korpus/.venv/lib/python3.12/site-packages/dhlab/api/dhlab_api.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "api.concordance??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a4e5925-45cb-4792-81a0-0f59a7d9056f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m\n",
       "api.urn_collocation(\n",
       "    urns: Optional[List[str]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    word: str = \u001b[33m'arbeid'\u001b[39m,\n",
       "    before: int = \u001b[32m5\u001b[39m,\n",
       "    after: int = \u001b[32m0\u001b[39m,\n",
       "    samplesize: int = \u001b[32m200000\u001b[39m,\n",
       ") -> pandas.core.frame.DataFrame\n",
       "\u001b[31mSource:\u001b[39m   \n",
       "\u001b[38;5;28;01mdef\u001b[39;00m urn_collocation(\n",
       "    urns: List[str] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    word: str = \u001b[33m\"arbeid\"\u001b[39m,\n",
       "    before: int = \u001b[32m5\u001b[39m,\n",
       "    after: int = \u001b[32m0\u001b[39m,\n",
       "    samplesize: int = \u001b[32m200000\u001b[39m,\n",
       ") -> DataFrame:\n",
       "    \u001b[33m\"\"\"Create a collocation from a list of URNs.\u001b[39m\n",
       "\n",
       "\u001b[33m    Call the API :py:obj:`~dhlab.constants.BASE_URL` endpoint\u001b[39m\n",
       "\u001b[33m    `/urncolldist_urn`.\u001b[39m\n",
       "\n",
       "\u001b[33m    :param list urns: list of uniform resource name strings, for example:\u001b[39m\n",
       "\u001b[33m        ``[\"URN:NBN:no-nb_digibok_2008051404065\", \"URN:NBN:no-nb_digibok_2010092120011\"]``\u001b[39m\n",
       "\u001b[33m    :param str word: word to construct collocation with.\u001b[39m\n",
       "\u001b[33m    :param int before: number of words preceding the given ``word``.\u001b[39m\n",
       "\u001b[33m    :param int after: number of words following the given ``word``.\u001b[39m\n",
       "\u001b[33m    :param int samplesize: total number of ``urns`` to search through.\u001b[39m\n",
       "\u001b[33m    :return: a ``pandas.DataFrame`` with distance (sum of distances and bayesian distance) and\u001b[39m\n",
       "\u001b[33m        frequency for words collocated with ``word``.\u001b[39m\n",
       "\u001b[33m    \"\"\"\u001b[39m\n",
       "\n",
       "    params = {\n",
       "        \u001b[33m\"urn\"\u001b[39m: urns,\n",
       "        \u001b[33m\"word\"\u001b[39m: word,\n",
       "        \u001b[33m\"before\"\u001b[39m: before,\n",
       "        \u001b[33m\"after\"\u001b[39m: after,\n",
       "        \u001b[33m\"samplesize\"\u001b[39m: samplesize,\n",
       "    }\n",
       "    r = api_post(BASE_URL + \u001b[33m\"/urncolldist_urn\"\u001b[39m, json=params)\n",
       "    \u001b[38;5;28;01mreturn\u001b[39;00m pd.read_json(StringIO(r.json()))\n",
       "\u001b[31mFile:\u001b[39m      ~/Github/bibel-korpus/.venv/lib/python3.12/site-packages/dhlab/api/dhlab_api.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "api.urn_collocation??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
